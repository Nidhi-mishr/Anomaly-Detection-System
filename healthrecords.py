# -*- coding: utf-8 -*-
"""HealthRecords.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12IwLxMJR3uWH9jy0sXvmeRwk3oVogzr_
"""

import pandas as pd
from google.colab import files

# Access the uploaded file
file_path = 'healthcare_dataset.csv'

try:
    df = pd.read_csv(file_path)
    print(df.head())
except FileNotFoundError:
    print(f"Error: File not found at {file_path}. Please ensure the file is uploaded to your Colab environment.")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
data=pd.read_csv("healthcare_dataset.csv")

data.head()

data.shape

data.describe()

data.info()

data_original = data.copy()

print(data.isnull().sum())

from sklearn.preprocessing import LabelEncoder, StandardScaler

# Clean column names
data.columns = data.columns.str.strip().str.lower().str.replace(' ', '_')

# Convert date columns and create 'days_since_admission'
data['date_of_admission'] = pd.to_datetime(data['date_of_admission'])
data['discharge_date'] = pd.to_datetime(data['discharge_date'])
data['days_since_admission'] = (data['discharge_date'] - data['date_of_admission']).dt.days
data.drop(columns=['date_of_admission', 'discharge_date'], inplace=True)

# Apply Label Encoding to categorical columns
categorical_columns = ['gender', 'blood_type', 'medical_condition', 'doctor', 'hospital',
                       'insurance_provider', 'admission_type', 'medication', 'test_results']
for col in categorical_columns:
    data[col] = LabelEncoder().fit_transform(data[col])

# Scale numerical features
numerical_features = ['age', 'billing_amount', 'room_number', 'days_since_admission']
data[numerical_features] = StandardScaler().fit_transform(data[numerical_features])

# Preview processed data
data.head()

# Verify and drop non-numeric columns
data = data.select_dtypes(include=['number'])  # Keep only numeric columns

from sklearn.ensemble import IsolationForest
from sklearn.metrics import precision_score, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt

# Step 1: Define feature matrix
X = data.values

# Step 2: Define true labels for evaluation (replace with actual labels if available)
true_labels = np.random.choice([0, 1], size=X.shape[0], p=[0.93, 0.07])

# Step 3: Manual hyperparameter tuning
best_precision = 0
best_params = None

# grid of hyperparameters
n_estimators_list = [450,550]
max_samples_list = [0.85,0.9]
contamination_list = [0.018,0.025,0.03]

for n_estimators in n_estimators_list:
    for max_samples in max_samples_list:
        for contamination in contamination_list:
            # Initialize and train the model
            iso_forest = IsolationForest(
                n_estimators=n_estimators,
                max_samples=max_samples,
                contamination=contamination,
                random_state=42
            )
            iso_forest.fit(X)

            predictions = iso_forest.predict(X)
            predictions = np.where(predictions == -1, 1, 0)

            precision = precision_score(true_labels, predictions)

            if precision > best_precision:
                best_precision = precision
                best_params = {
                    'n_estimators': n_estimators,
                    'max_samples': max_samples,
                    'contamination': contamination
                }

# Step 4: Train final model with best parameters
final_model = IsolationForest(**best_params, random_state=42)
final_model.fit(X)

# Step 5: Adjust decision function threshold
threshold = 0.02
decision_function_values = final_model.decision_function(X)
predictions = np.where(decision_function_values < threshold, 1, 0)

data['anomaly'] = predictions

# Step 6: Visualize anomalies
plt.figure(figsize=(10, 6))
plt.scatter(data.index, decision_function_values, c=data['anomaly'], cmap='coolwarm', alpha=0.7)
plt.colorbar(label='Anomaly Score')
plt.xlabel('Record Index')
plt.ylabel('Decision Function Value')
plt.title('Anomaly Scores with Isolation Forest')
plt.show()

# Step 7: Evaluation of final model
precision = precision_score(true_labels, data['anomaly'])
accuracy = accuracy_score(true_labels, data['anomaly'])
cm = confusion_matrix(true_labels, data['anomaly'])

print("Best Parameters:", best_params)
print("Precision:", precision)
print("Accuracy:", accuracy)
print("Confusion Matrix:\n", cm)

from sklearn.model_selection import cross_val_score
from sklearn.metrics import roc_curve, auc

# Cross-validation to evaluate the stability of the model
cross_val_scores = cross_val_score(final_model, X, true_labels, cv=5, scoring='accuracy')
print(f"Cross-Validation Accuracy Scores: {cross_val_scores}")
print(f"Mean Cross-Validation Accuracy: {np.mean(cross_val_scores)}")

# ROC Curve and AUC
fpr, tpr, thresholds = roc_curve(true_labels, final_model.decision_function(X))
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc='lower right')
plt.show()

print(f"AUC-ROC: {roc_auc}")

from sklearn.svm import OneClassSVM
from sklearn.metrics import precision_score, accuracy_score, confusion_matrix

# Step 1: Train the One-Class SVM model
one_class_svm = OneClassSVM(nu=0.03, kernel="rbf", gamma='scale')
one_class_svm.fit(X)

# Step 2: Make predictions
svm_predictions = one_class_svm.predict(X)
svm_predictions = np.where(svm_predictions == -1, 1, 0)

# Step 3: Evaluate the performance
precision = precision_score(true_labels, svm_predictions)
accuracy = accuracy_score(true_labels, svm_predictions)
cm = confusion_matrix(true_labels, svm_predictions)

print("Precision:", precision)
print("Accuracy:", accuracy)
print("Confusion Matrix:\n", cm)

# Step 1: Visualize Anomaly Scores
anomaly_scores = one_class_svm.decision_function(X)

# Step 2: Plot Anomaly Scores with Predictions
plt.figure(figsize=(10, 6))
plt.scatter(range(len(anomaly_scores)), anomaly_scores, c=svm_predictions, cmap='coolwarm', alpha=0.7)
plt.colorbar(label='Anomaly Score')
plt.xlabel('Record Index')
plt.ylabel('Anomaly Score')
plt.title('Anomaly Scores with One-Class SVM')
plt.show()

from sklearn.neighbors import LocalOutlierFactor
from sklearn.metrics import precision_score, accuracy_score, confusion_matrix

# Step 1: Initialize and fit LOF
lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05, novelty=True)
lof.fit(X)
# Step 2: Predict anomalies
lof_predictions = lof.predict(X)
lof_predictions = np.where(lof_predictions == -1, 1, 0)

# Step 3: Evaluate the model
precision = precision_score(true_labels, lof_predictions)
accuracy = accuracy_score(true_labels, lof_predictions)
cm = confusion_matrix(true_labels, lof_predictions)

print("LOF Precision:", precision)
print("LOF Accuracy:", accuracy)
print("Confusion Matrix:\n", cm)

lof_scores = -lof.negative_outlier_factor_
plt.figure(figsize=(10, 6))
plt.scatter(range(len(lof_scores)), lof_scores, c=lof_predictions, cmap='coolwarm', alpha=0.7)
plt.colorbar(label='LOF Score')
plt.xlabel('Record Index')
plt.ylabel('LOF Score')
plt.title('Anomaly Scores with Local Outlier Factor')
plt.show()

import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score, accuracy_score, confusion_matrix

# Assuming data is preprocessed and X is your feature matrix
X = data.values  # Use your preprocessed data here

# Step 1: Scale the data (optional but recommended)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 2: Define the Autoencoder model
input_dim = X_scaled.shape[1]  # Number of features in the dataset

autoencoder = tf.keras.Sequential([
    tf.keras.layers.InputLayer(input_shape=(input_dim,)),  # Input layer with correct shape
    tf.keras.layers.Dense(32, activation='relu'),          # Encoding layer 1
    tf.keras.layers.Dense(16, activation='relu'),          # Encoding layer 2
    tf.keras.layers.Dense(8, activation='relu'),           # Bottleneck layer (lowest dimension)
    tf.keras.layers.Dense(16, activation='relu'),          # Decoding layer 1
    tf.keras.layers.Dense(32, activation='relu'),          # Decoding layer 2
    tf.keras.layers.Dense(input_dim, activation='sigmoid') # Output layer (reconstructed data)
])

# Step 3: Compile the model
autoencoder.compile(optimizer='adam', loss='mse')  # Mean Squared Error for reconstruction loss

# Step 4: Train the Autoencoder
autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=32, validation_split=0.2)

# Step 5: Predict the reconstructed data
reconstructed = autoencoder.predict(X_scaled)

# Step 6: Calculate reconstruction errors
reconstruction_errors = np.mean(np.abs(X_scaled - reconstructed), axis=1)

# Step 7: Set a threshold for anomalies (you can tune this value)
threshold = np.percentile(reconstruction_errors, 97)  # Anomalies above the 95th percentile

# Step 8: Predict anomalies
predictions = (reconstruction_errors > threshold).astype(int)

# Step 9: Evaluate performance
# Assuming you have true labels (replace with actual labels if available)
true_labels = np.random.choice([0, 1], size=X.shape[0], p=[0.95, 0.05])

precision = precision_score(true_labels, predictions)
accuracy = accuracy_score(true_labels, predictions)
cm = confusion_matrix(true_labels, predictions)

# Step 10: Print results
print("Precision:", precision)
print("Accuracy:", accuracy)
print("Confusion Matrix:\n", cm)

# Step 11: Visualize reconstruction errors
plt.figure(figsize=(10, 6))
plt.hist(reconstruction_errors, bins=50, color='blue', alpha=0.7)
plt.axvline(threshold, color='red', linestyle='--')
plt.xlabel('Reconstruction Error')
plt.ylabel('Frequency')
plt.title('Histogram of Reconstruction Errors')
plt.show()

from scipy.stats import mode

# Combine predictions (Example: Isolation Forest, One-Class SVM, LOF)
combined_predictions = np.array([
    data['anomaly'].values,  # Isolation Forest predictions
    svm_predictions,         # One-Class SVM predictions
    lof_predictions           # LOF predictions
])

# Take majority vote
ensemble_predictions = mode(combined_predictions, axis=0).mode.flatten()

# Evaluate Ensemble Model
precision = precision_score(true_labels, ensemble_predictions)
accuracy = accuracy_score(true_labels, ensemble_predictions)
cm = confusion_matrix(true_labels, ensemble_predictions)

print("Ensemble Precision:", precision)
print("Ensemble Accuracy:", accuracy)
print("Confusion Matrix:\n", cm)